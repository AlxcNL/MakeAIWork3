{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2ad83ef-4ee3-4463-9b5e-127f12237363",
   "metadata": {},
   "source": [
    "<a href=\"https://it-omscholing.nl/locaties/hogeschool-rotterdam/\">\n",
    "<div>\n",
    "<a><img src='../../pics/banner.PNG'/></a>\n",
    "</div>\n",
    "<div>\n",
    "<a href=''><img src='../../pics/miw.PNG'/></a>\n",
    "</div>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf243b00-2d08-48b7-85cf-b9f2c288d81d",
   "metadata": {},
   "source": [
    "# Practicum Convolution Neural Nets (CNN)\n",
    "\n",
    "**Doel: Toepassen Convolutional Neural Networks**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f0beb08-683b-4d1a-8a3b-7c2938aef74f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2ed2f-2d11-4d51-a10f-02ff61588ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef8f9f9b-8024-493f-aa94-b6eb3ad10184",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Globale variabelen</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae222e-fc69-47b6-bb65-ad38f29c38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "riverDirectory = '../../pics/2750/River'\n",
    "highwayDirectory = '../../pics/2750/Highway'\n",
    "industrialDirectory = '../../pics/2750/Industrial'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab893eb4-4667-409f-9f7d-1f2e708be670",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "<p>\n",
    "Dit practicum bestaat uit twee onderdelen\n",
    "<ol>\n",
    "    <li>Het toepassen van een convolutie en pooling filter</li>\n",
    "    <li>Het bouwen en trainen van een eenvoudig convolutional neural net dat een industrieterrein van een bos kan onderscheiden. Voor beide oefeningen gebruiken we de EuroSAT_RGB dataset</li>\n",
    "</p>\n",
    "\n",
    "<img src='../../pics/eurosat_cnn.png' length=60% width=60%>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5305365c-a61c-4dea-adf8-2e9dddef9b82",
   "metadata": {},
   "source": [
    "<h3>Data Collection</h3>\n",
    "<p>\n",
    "We gebruiken Images uit de <a href=\"https://github.com/phelber/EuroSAT\">EuroSat dataset</a> die gemaakt zijn met de Sentinel-2 sateliet. Elke image is een 64x64 pixels foto van Europees aardoppervlak op een hoogte van 10 meter. De images zijn te categoriseren in Highway, Industrial, Pasture, PermanentCrop, Residential, River en SeaLake.\n",
    "</p>\n",
    "<img src=../../pics/eurosat_overview_small.jpg length=40% width=40%>\n",
    "<p>\n",
    "Download <a href=\"http://madm.dfki.de/files/sentinel/EuroSAT.zip\">EuroSAT.zip</a> en kopieer daaruit de directory 2750 naar opdrachten/practica/pics.      \n",
    "<strong>Voeg het pad naar de directory 2750 toe aan .gitignore zodat je de plaatjes niet naar je remote git repository pusht</strong>\n",
    "</p>    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5da250e7-2075-411c-b097-6bf232981619",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Opdrachten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41b5b973-72e7-4159-88eb-ea86258a26fd",
   "metadata": {},
   "source": [
    "### Opdracht 1: Afbeelding inladen\n",
    "\n",
    "PyTorch Vision maakt het inladen van afbeeldingen gemakkelijk via:\n",
    "\n",
    "https://pytorch.org/vision/stable/io.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ea14f80-0831-4620-8c4c-280047047bc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>\n",
    "Bekijk de documentatie van de <i>PyTorch io module</i> en laad de afbeelding 'Industrial_1.jpg' in variable <u>industrial</u> als een 1-dimensionale Torch Tensor met float (Scalar) waarden.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3504f-8d2c-488f-bc10-aa94d70a0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oplossing\n",
    "\n",
    "industrial = read_image( \n",
    "    f\"{industrialDirectory}/Industrial_1.jpg\", \n",
    "    ImageReadMode.UNCHANGED\n",
    ").float()\n",
    "\n",
    "industrial.shape\n",
    "type(industrial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9380530f-1361-4def-986a-15fe316cc63f",
   "metadata": {},
   "source": [
    "### Opdracht 2: convolutie + padding uitvoeren\n",
    "\n",
    "<p>\n",
    "De basis-ingrediÃ«nten van een CNN, convolutie en pooling, hebben we al met de hand uitgevoerd tijdens het practicum Numpy 2.\n",
    "Ditmaal voeren we een convolutie filter uit met <a href=\"https://pytorch.org/docs/stable/nn.functional.html\">PyTorch Functional</a>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765ee9d7-b86b-4e33-8783-981a57019bc6",
   "metadata": {},
   "source": [
    "<p>\n",
    "Maak een <a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">3 x 3 kernel</a> om een edge te detecteren en representeer de kernel als een Pytorch Tensor met naam <u>edgeFilter</u>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e55e7-c6a7-4a9b-a38f-83db18d5d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With square kernels and equal stride\n",
    "edgeFilter = torch.Tensor(\n",
    "        [\n",
    "            [-1, -1, -1], \n",
    "            [-1,  8, -1], \n",
    "            [-1, -1, -1]\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd1d2a17-1c9c-472c-a55e-fba7d1ba2977",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Maak o.b.v. <u>edgeFiler</u> een Conv2d filter met als\n",
    "    <ul>\n",
    "        <li>stride 1 (default) geeft aan hoeveel de kernel verplaatst per stap</li>\n",
    "        <li>padding 0 (default) geeft aan hoe we omgaan met de randen</li>\n",
    "        <li>naam <u>edgeConv</u></li>\n",
    "    </ul>\n",
    "</p>            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569e457-5497-4282-86c8-1d634bf4f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgeFilter = torch.Tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]]).unsqueeze(0).unsqueeze(0)\n",
    "edgeFilter.requires_grad = True\n",
    "edgeConv = nn.Conv2d(3, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight = nn.Parameter(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c62035-ea2b-4f44-a2cc-7d48c757b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Pas je ontworpen filter toe op 'Industrial_1.jpg'\n",
    "industrialFiltered = edgeConv(industrial)\n",
    "\n",
    "# g. Herhaal bovenstaande stappen voor een plaatje dat je bij Numpy Opdracht 2 hebt gebruikt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21634fcd-a9e7-428a-9758-ab6801b3c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "plt.imshow (\n",
    "    np.squeeze ( industrialFiltered.detach() )   \n",
    ")        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6574b602-78bb-4bd0-b52b-5508f69cbbaf",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Zijn 'Industrial_1.jpg' en 'Forrest_1.jpg' na een convolutie beter te onderscheiden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317397a-a336-4c5e-8cf3-02fc7d5c6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: varieer de stride en de padding en toon de resultaten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94c91d7-d9a1-4e73-9f13-ada5e0e3324d",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Wat is de invloed van padding en stride op de uitkomst?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0b72b5-c897-46c1-bef7-033a0881f548",
   "metadata": {},
   "source": [
    "### Opdracht 3: pooling uitvoeren\n",
    "\n",
    "Met PyTorch Functional kunnen we ook een pooling filter toepassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a85a20-7ca7-49c2-a309-19044ddd6bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Bekijk de pooling opties en kies de juiste avg-variant\n",
    "\n",
    "# b. Pas pooling toe op de afbeelding 'Industrial_1.jpg':\n",
    "\n",
    "#    - Kies een 3x3 kernel en een stride van 1\n",
    "\n",
    "# c. Herhaal de bovenstaande stappen voor een willekeure Forest Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36a09543-15ad-4222-9051-5aa536955c3b",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Komt de visuele uitkomst overeen met je verwachtingen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75fe4ef-1016-4e0a-8657-8b662c58cc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extra: varieer de stride en de kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b93dbb9-53e0-4afa-b83b-70028c73f30f",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Wat is de invloed van padding en stride op de uitkomst?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2054047a-79ca-4fe0-bd17-2de8ded73320",
   "metadata": {},
   "source": [
    "### Opdracht 4: convolutie en pooling combineren\n",
    "\n",
    "Een convolutional neural net combineert afwisselend convolutie en pooling in de eerste lagen.\n",
    "\n",
    "We kunnen nu het effect van deze combinatie onderzoeken:\n",
    "\n",
    "- Convolutie\n",
    "- Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266c837-6e9b-4e43-9537-bc576e45df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Bedenk en maak zelf een 2d convolution filter\n",
    "\n",
    "# b. Bedenk en maak zelf een 2d pooling filter\n",
    "\n",
    "# c. Pas nu de convolutie toe op 'Industrial_1.jpg'\n",
    "\n",
    "# d. Pas vervolgens een pooling toe op de uitkomst van c.\n",
    "\n",
    "# e. Doe hetzelfde voor de afbeelding 'Forrest_1.jpg'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d444bfc7-3460-427d-b6a3-2f498ef2813e",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "- Verschilt de uitkomst veel van de combinatie veel met convolutie en pooling?\n",
    "- En zijn de afbeeldingen 'Industrial_1.jpg' en 'Forrest_1.jpg' beter te onderscheiden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c29fd-3908-4d3b-8cb3-694f8c717c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: bereid de combinatie uit met nog een extra convolutie en pooling laag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8243671-21a0-45b2-883a-6c9ab35756f1",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Heeft een extra laag veel invloed op de onderscheidbaarheid van de afbeeldingen?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd748ec9-c052-43ba-8a7f-110e47542d92",
   "metadata": {},
   "source": [
    "### Opdracht 5: dataset prepareren\n",
    "\n",
    "Om het neurale netwerk te trainen moeten we de dataset opsplitsen in labels (Y, de categoriÃ«n) en input afbeeldingen (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563c265-e471-4f8b-a388-4da8229c5067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Denk nog eens terug aan hoe we kruisjes van rondjes van elkaar konden onderscheiden\n",
    "\n",
    "#    - Hoe representeerden we de labels?\n",
    "#    - Hoe representeerden we de kruisjes en de rondjes?\n",
    "#    - Hoe combineerden we dit tot een dataset?\n",
    "\n",
    "# b. Hoe kunnen we de labels 'Industrials' en 'Forrest' dus representeren?\n",
    "\n",
    "# c. Vorm nu een dataset voor 'Industrials' en 'Forrest'\n",
    "\n",
    "# d. Extra: implementeer bovenstaande via een Dataset en DataLoader class\n",
    "#           (zie https://pytorch.org/docs/stable/data.html voor verdere details)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "213813ff-a44d-427f-bb16-661673e8a333",
   "metadata": {},
   "source": [
    "### Opdracht 6: CNN ontwerpen\n",
    "\n",
    "We kunnen een convolutional neural net opbouwen met convolutie, pooling en fully connected lagen. Hieronder definiÃ«ren we een topologie om een afbeeldingen van 32 x 32 te onderscheiden.\n",
    "\n",
    "De topologie is gebaseerd op de blog post 'A simple CNN with Pytorch'. Dus zie het artikel voor extra details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a84b2a-3058-459d-8fb5-3fe8d0a7b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Because we inherit from Module base class\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB input, 6 filters, kernel of 5 x 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # in_channels = 6 because self.conv1 output has 6 channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layer matched on output of conv2 layer\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # We only have 2 labels\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        \n",
    "    #-------------------------------------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution with relu layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # To match the output of the conv2 layer onto the first fully connected layer\n",
    "        # Like reshape() but makes no copy (reuses underlaying data)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # No activation on final layer \n",
    "        return self.fc3(x)\n",
    "\n",
    "#-------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3248f8b9-64b2-4cf4-ab9f-bcc74c8076db",
   "metadata": {},
   "source": [
    "### Opdracht 7: CNN trainen\n",
    "\n",
    "Het trainen van een CNN is identiek aan het trainen van een fully connected (a.k.a. dense) netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64e93d-e9e2-49d3-b047-20afb4887f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Ga voor jezelf na welke stappen een typisch trainingsproces bevat\n",
    "\n",
    "# b. Bekijk de blog post 'A simple CNN in Python' en zet de training op\n",
    "\n",
    "# c. Het voorbeeld bevat geen validatie tijdens de trainingsstap (epoch)\n",
    "\n",
    "#    - Bekijk het Notebook met de de postcode FastScan\n",
    "#      en bereid de training uit met validatie in de trainingsloop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e503bc56-46d6-4e15-8d91-d7784edc5e2b",
   "metadata": {},
   "source": [
    "### Opdracht 8: dropout toevoegen\n",
    "\n",
    "Om het netwerk effectiever te trainen wordt dropout toegepast.\n",
    "\n",
    "PyTorch maakt het toevoegen van dropout makkelijk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d98c7a-3358-4937-8bc0-fd8b003121c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Bekijk het artikel Using Dropout Regularization in PyTorch Models (zie sources)\n",
    "\n",
    "# b. Pas nu dropout toe op een hidden layer van je model\n",
    "\n",
    "# c. Hertrain je model\n",
    "\n",
    "#    - Let er op dat je je model evalueert in eval() mode\n",
    "#    - Heeft de dropout invloed op de accuracy van je model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f91aa1cc-60c9-481b-9d66-3ab359b7422a",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "- Wat gebeurt er als de dropout groot is (bijvoobeeld 0.9)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b682a804-e1f7-4b9d-a3fe-2de933c32f44",
   "metadata": {},
   "source": [
    "### Bronnen\n",
    "\n",
    "[EuroSAT project](https://github.com/phelber/eurosat)\n",
    "\n",
    "[Pytorch Neural Nets](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "[Kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "\n",
    "[A simple CNN with Pytorch](https://tomroth.com.au/pytorch-cnn)\n",
    "\n",
    "[A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "\n",
    "[Using Dropout Regularization in PyTorch Models](https://machinelearningmastery.com/using-dropout-regularization-in-pytorch-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011d836-3759-4d16-b639-019754144a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
