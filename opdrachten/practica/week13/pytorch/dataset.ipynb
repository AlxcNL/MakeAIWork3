{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f24a51b1-15f1-4ae4-9bb6-464af399d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image, ImageReadMode\n",
    "from os import path, listdir\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4aa0ef9b-c266-4fb8-acc9-e609c57e58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrialDirectory = '../../pics/2750/Industrial'\n",
    "fileList = list()\n",
    "\n",
    "for fileName in listdir(industrialDirectory):\n",
    "    imgFile = path.join(industrialDirectory, fileName)\n",
    "\n",
    "    if \".jpg\" in imgFile:\n",
    "        fileList.append(imgFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90c9319f-b37f-4874-8b34-c02a5152fe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67e84739-9b86-41fd-bbdf-63021d2144bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgPathToTensor(imgPath):\n",
    "    return read_image(imgPath, ImageReadMode.GRAY).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e8f799b-0e5e-4ae1-a5ca-c3848e82336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/jvyzks7j1qg_f06xnf_730740000gn/T/ipykernel_77775/94420411.py:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  imgTensors = np.asarray(imgList)\n",
      "/var/folders/c0/jvyzks7j1qg_f06xnf_730740000gn/T/ipykernel_77775/94420411.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  imgTensors = np.asarray(imgList)\n"
     ]
    }
   ],
   "source": [
    "imgList = list()\n",
    "\n",
    "for imgPath in fileList:\n",
    "    imgList.append(imgPathToTensor(imgPath))\n",
    "    \n",
    "imgTensors = np.asarray(imgList)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "128023ee-00e3-4692-9db8-4787cf72f383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[106., 106., 103.,  ...,  88.,  87.,  86.],\n",
       "         [106., 106., 102.,  ...,  88.,  87.,  86.],\n",
       "         [103., 102.,  98.,  ...,  95.,  96.,  95.],\n",
       "         ...,\n",
       "         [101., 101.,  88.,  ..., 255., 255., 255.],\n",
       "         [ 94.,  94.,  86.,  ..., 255., 255., 255.],\n",
       "         [ 86.,  87.,  81.,  ..., 255., 255., 255.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# len(imgTensors)\n",
    "display(imgTensors[0])\n",
    "# imgTensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f910f-67cc-4012-99fe-a8fc056cf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating dummy targets (float values)\n",
    "# targets_data = [random.random() for i in range(10)]\n",
    "\n",
    "# # creating DataFrame from targets_data\n",
    "# targets_df = pd.DataFrame(data=targets_data)\n",
    "# targets_df.columns = ['targets']\n",
    "\n",
    "# # creating tensor from targets_df \n",
    "# torch_tensor = torch.tensor(targets_df['targets'].values)\n",
    "\n",
    "# # printing out result\n",
    "# print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bac65-499e-49e2-8274-78c8d8e5deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "dataset = TensorDataset(inps, tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "02a864fe-0051-402c-807e-f70efec17feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m at \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(a)\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39mTensorDataset( \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgTensors\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(imgTensors) )\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "at =torch.from_numpy(a)\n",
    "\n",
    "dataset = data_utils.TensorDataset( torch.from_numpy(imgTensors), torch.from_numpy(imgTensors) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e4d80-30e1-4467-b007-c9b765f6e3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
