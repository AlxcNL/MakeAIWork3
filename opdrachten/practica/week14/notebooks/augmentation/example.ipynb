{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ad390d-19c7-45dd-8721-75853262cb59",
   "metadata": {},
   "source": [
    "<a href=\"https://it-omscholing.nl/locaties/hogeschool-rotterdam/\">\n",
    "<div>\n",
    "<a><img src='../../../pics/banner.PNG'/></a>\n",
    "</div>\n",
    "<div>\n",
    "<a href=''><img src='../../../pics/miw.PNG'/></a>\n",
    "<em>Author: Jeroen Boogaard</em>\n",
    "</div>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17511c-0c6b-4edf-a0e4-9183307fbdb5",
   "metadata": {},
   "source": [
    "<h2>Voorbeeld image augmentation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb256d-8dcb-439b-a6bb-57d9f9d65d75",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48fc3902-0d98-4ada-8527-a6b2e84f3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a87a0-c1b5-4388-bc57-532a0dd0599a",
   "metadata": {},
   "source": [
    "<h3>Global variabels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb017b15-88fa-48ee-aebd-0dadfe0614d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forestDirectory = '../../../pics/2750/Forest'\n",
    "residentialDirectory = '../../../pics/2750/Residential'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4645a9c-a496-4325-b076-0616e7476fe8",
   "metadata": {},
   "source": [
    "<h3>Data Collection</h3>\n",
    "<p>\n",
    "We gebruiken Images uit de <a href=\"https://www.kaggle.com/datasets/apollo2506/eurosat-dataset\">EuroSat dataset</a> die gemaakt zijn met de Sentinel-2 sateliet. Elke image is een 64x64 pixels foto van Europees aardoppervlak op een hoogte van 10 meter. De images zijn te categoriseren in Highway, Industrial, Pasture, PermanentCrop, Residential, River en SeaLake.\n",
    "</p>\n",
    "<img src=../../../pics/eurosat_overview_small.jpg length=50% width=50%>\n",
    "<p>\n",
    "Download <a href=\"http://madm.dfki.de/files/sentinel/EuroSAT.zip\">EuroSAT.zip</a> en kopieer daaruit de directory 2750 naar opdrachten/practica/pics.      \n",
    "<strong>Voeg het pad naar de directory 2750 toe aan .gitignore zodat je de plaatjes niet naar je remote git repository pusht</strong>\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5331e00-0ec0-48f3-b154-49ab9d4f69d1",
   "metadata": {},
   "source": [
    "<h3>Data Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e45bdc-e3d4-464e-8017-08e0ff5ceecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "landFiles = list()\n",
    "landLabels = list()\n",
    "    \n",
    "for fileName in listdir(residentialDirectory):\n",
    "    imgFile = path.join(residentialDirectory, fileName)\n",
    "\n",
    "    if \".jpg\" in imgFile:\n",
    "        landFiles.append(imgFile)\n",
    "        landLabels.append(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b3aea1c-7944-4566-a10a-09512598ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandDataset(Dataset):\n",
    "    def __init__(self, imagePaths, transform=False):\n",
    "        self.image_paths = imagePaths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Use Pahtlib\n",
    "        label = image_filepath.split('/')[-2]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bedc4-da89-4b4e-92df-84fc68a220ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "landTransforms = transforms.Compose (\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize( (256, 256) ),\n",
    "        transforms.RandomCrop( (224, 224) ),\n",
    "        transforms.ColorJitter(brightness=0.5),\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.05),\n",
    "        transforms.ToTensor()\n",
    "    ]    \n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54aaaa-ea6c-4784-bb62-442db6a75047",
   "metadata": {},
   "outputs": [],
   "source": [
    "landDataset = LandDataset(residentialDirectory, transform=landTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e0c81-65cd-462d-92a1-ba673d62242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of tensor for 50th image in train dataset: ',landDataset[49][0].shape)\n",
    "# print('The label for 50th image in train dataset: ',landDataset[49][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae271d4-883c-47a8-ab02-fd4e2e879aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in landDataset:\n",
    "    augImgFile = \"tes.jpg\"\n",
    "    save_image(img, augImgFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7f937-6da5-470e-a6c6-0232e388df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, idx=0, samples=10, cols=5, random_img = False):\n",
    "    \n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    #we remove the normalize and tensor conversion from our augmentation pipeline\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    \n",
    "        \n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 8))\n",
    "    for i in range(samples):\n",
    "        if random_img:\n",
    "            idx = np.random.randint(1,len(train_image_paths))\n",
    "        image, lab = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "        ax.ravel()[i].set_title(idx_to_class[lab])\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.show()    \n",
    "\n",
    "visualize_augmentations(train_dataset,np.random.randint(1,len(train_image_paths)), random_img = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65088d-fda5-4e31-804b-8f52144564e9",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/custom-dataset-in-pytorch-part-1-images-2df3152895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ff95d-29dc-46d0-8f30-53b6d7c7fb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
